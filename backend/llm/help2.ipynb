{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32b385c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "5361.35s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (2.7.0)\n",
      "Requirement already satisfied: tiktoken in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (0.9.0)\n",
      "Requirement already satisfied: sentencepiece in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (0.2.0)\n",
      "Requirement already satisfied: blobfile in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (3.0.0)\n",
      "Requirement already satisfied: datasets in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (3.6.0)\n",
      "Requirement already satisfied: networkx in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: filelock in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: fsspec in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: jinja2 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: pycryptodomex>=3.8 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from blobfile) (3.23.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from blobfile) (2.4.0)\n",
      "Requirement already satisfied: lxml>=4.9 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from blobfile) (5.4.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: packaging in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from datasets) (0.31.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pandas in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from fsspec->torch) (3.11.18)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (5.0.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (0.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (25.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.20.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (2.6.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (6.4.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch tiktoken sentencepiece blobfile datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b3757b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45ef6293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa66900047d46838fbb8f879cbeda86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabb35d8fd88445685090beadb8de097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a78318119de4a069e1ed690c760da84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd1b1634ecb342a59c599232836ed008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed70d2d42f2432bbdba1db68a2cea78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2051a32fe9fa4eb0b13635cf05a25227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1f29c6135f486d99ed258da604673b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2-medium\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2-medium\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb61cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split into 90% train and 10% validation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9a409402e94fe4976a2dee9f0b8dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434d9f80540f41078e2a5bc3f44e309b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad38e060aea44d8a3918f3c637b5eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945dfc4b062d4bfab16dd89e3b356009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7fbd0a33db44fe9b305b58c6c0afd16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79c19b1854f44c69e97c68a5e9a3d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b107fb9b0244138ba9c257f50a6fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b1d7f14f44468c84ed042dca987267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2299 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1d961909d44ecfaeea35ac6574faff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1725' max='1725' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1725/1725 20:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.472600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.023200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.830900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/rachitrustagi/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1725, training_loss=1.064494142394135, metrics={'train_runtime': 1266.3176, 'train_samples_per_second': 5.447, 'train_steps_per_second': 1.362, 'total_flos': 450532786176000.0, 'train_loss': 1.064494142394135, 'epoch': 3.0})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"KadamParth/NCERT_Science_9th\")\n",
    "\n",
    "if \"validation\" not in dataset:\n",
    "    dataset = dataset[\"train\"].train_test_split(test_size=0.1)\n",
    "    print(\"Dataset split into 90% train and 10% validation.\")\n",
    "# Load GPT-2 Medium model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",  # Use GPU if available\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "# Tokenize the dataset (using Explanation column)\n",
    "def tokenize_function(examples):\n",
    "    tokens = tokenizer(examples[\"Explanation\"], \n",
    "                       truncation=True, \n",
    "                       padding=\"max_length\", \n",
    "                       max_length=128)\n",
    "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()  # Set labels as a copy of input_ids\n",
    "    return tokens\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"Explanation\"])\n",
    "# Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-science-finetuned\",\n",
    "    # evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,  # Adjust for your system\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=3,\n",
    "    fp16=torch.cuda.is_available(),  # Mixed precision training if GPU available\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],  # The split test is used as validation\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "410d07d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 Fine-Tuned Model Ready for Testing!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: it is the movement of water molecules from a region of high water concentration to a region of low water concentration through a semipermeable membrane. This process is crucial for the regulation of water in living organisms. Osmosis is the movement of water molecules from a region of low water concentration to a region of high water concentration through a semipermeable membrane. This process is crucial for the regulation of food and water in living organisms. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: unit of time (tz) where time is the total time taken. In the given example, acceleration is calculated as (v = ut) where ut is the final time, v is the final velocity, and a is the time. The SI unit of time is the time (tz). The unit of time is the centripetal force (F). \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: acceleration is the change in velocity of an object over time. It is the change in position or direction of the velocity-time graph. It is a scalar quantity and does not have any fixed direction. It is the product of the velocity-time graph and the acceleration. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: Sir Isaac Newton\n",
      "Sir Isaac Newton was a mathematician known for his groundbreaking work on the structure of atoms. He formulated the laws of conservation of mass and the law of definite proportions, which laid the foundation for the modern understanding of matter. He was a pivotal figure in the development of atomic theory, the development of atomic mass units, the development of the concept of a nucleus, and the development of quantum mechanics. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: Sir Isaac Newton. Newton was a natural philosopher, mathematician, and astronomer. He was a leading scientist in his day. He used to study the structure of atoms and molecules in his laboratory. He formulated the law of definite definite definite proportions, which allowed definite proportions to be formulated. He also provided the first law of definite definite definite proportions, which made definite proportions definite in the presence of other factors. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: Sir Isaac Newton. Newton was a renowned physicist and mathematician. He formulated the laws of universal gravitation, which were fundamental in understanding the properties of matter. He also directed the development of atomic theory, which laid the foundation for understanding matter's properties. James Clerk Maxwell was a leading mathematician and a leading force in the development of atomic theory. James Rutherford also directed the development of the Rutherford-Kripke principle. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: There is no consensus on this point. The discovery of cell nucleus (cN) was a pivotal event in the nuclear physics of the atom. It laid the groundwork for the development of atomic theory, atomic mass, and the laws of conservation of mass. Rutherford's atomic model, also known as the Leiden model, provided crucial insights into the structure of the atom and its chemical reactions. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: Oh, no, no, no. It's not me. It's a scientist. This is a brain. This is a piece of paper. This is what you have discovered. This is the DNA of a cell. It's a part of your brain. You have a piece of paper and it says, \"This cell discovered this chemical compound by studying its structure and function.\" This is your brain. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: plasmolysis is the movement of a liquid from a region of high concentration to a region of low concentration through a semipermeable membrane. This process is crucial for the regulation of cellular activities and the exchange of gases and liquids. Plasmolysis is a type of cell division that results in two daughter cells, one with a fixed nucleus, and the other with a membrane-bound organelle called the endoplasmic reticulum. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: No plasmolysis process is required in this scenario. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: Plasmolysis is the process by which a liquid changes into a gas or vapor. It occurs when a substance (such as a liquid or gas) dissolves into a gas or vapor. This process is crucial for comprehending the properties and behaviors of gases and liquids. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: it is the movement of water molecules from a region of high water concentration to a region of low water concentration through a semipermeable membrane. Osmosis is a type of membrane-bound organelles found in plant cells. They are involved in photosynthesis and the storage of water in the cell membrane. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: It is the law of conservation of mass, formulated by Sir Isaac Newton. It states that mass cannot be created or destroyed, only transformed from one form to another. This means that the total mass of an object remains constant over time, even if some changes occur. This fundamental principle is fundamental in understanding the conservation of mass of substances and is a key component of Newton's Laws of Motion. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: Matter is composed of tiny particles called atoms. Each atom has a unique number of protons, neutrons, and electrons. Protons are the most common, with neutrons leading the charge and electrons leading the charge. Electrons are the least common, with neutrons leading the charge and electrons leading the charge. These states determine the mass of the atom and its components. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: Photosynthesis is the process by which green plants use sunlight to synthesize their energy. When plants plant roots, leaves, and flowers, they use sunlight to convert sunlight energy into chemical energy. This process is crucial for the production of photosynthesis-free energy in plants. Photosynthesis is a fundamental concept in chemistry and physics, and it is crucial for understanding the complex interactions between different organic and non-organic components. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: A atom is a fundamental unit of the physical universe. It consists of atoms of the same element and is the fundamental unit of matter. The discovery of electrons by Albert Einstein in 1897 led to the realization that matter is composed of tiny, indivisible particles called electrons. This led to the concept of a single electron, which later led to the concept of mass. The discovery of protons and neutrons by J.J. Thomson, who later refined atomic theory, provided the basis for the modern understanding of matter. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: Matter is composed of tiny particles called atoms. These particles are charged and vibrating, which make them incredibly strong and resistant to any physical force. These particles are called atoms because they have a single electron and a small number of neutrons. These atoms are called neutrons because they have a single electron and a large number of neutrons. \n",
      "\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Load the tokenizer (ensure it is saved in the main directory)\n",
    "base_model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "tokenizer.save_pretrained(\"./gpt2-science-finetuned\")  # Save tokenizer to the main directory\n",
    "\n",
    "# Load the fine-tuned model from the latest checkpoint\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./gpt2-science-finetuned/checkpoint-1725\")\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"GPT-2 Fine-Tuned Model Ready for Testing!\\n\")\n",
    "\n",
    "# Infinite test loop\n",
    "while True:\n",
    "    user_question = input(\"Ask your science question (or type 'exit' to quit): \")\n",
    "    if user_question.lower() == \"exit\":\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Prepare the input\n",
    "    input_text = f\"Q: {user_question}\\nA:\"\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "    # Generate the answer\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids, \n",
    "            max_length=128, \n",
    "            num_return_sequences=1, \n",
    "            temperature=0.7,  # Controls randomness (0.7 is balanced)\n",
    "            top_p=0.9,        # Nucleus sampling\n",
    "            do_sample=True,   # Enable sampling for creativity\n",
    "        )\n",
    "    \n",
    "    # Decode and display the answer\n",
    "    answer = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    print(\"\\nAnswer:\", answer.split(\"A:\")[-1].strip(), \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
